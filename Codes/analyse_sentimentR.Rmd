---
title: "R Notebook"
output: html_notebook
---



```{r}
#vider la mémoire
rm(list=ls())

#changer de dossier courant
# setwd("C:/Users/ricco/Desktop/demo")

#charger les packages de l'univers Tidy
#en particulier dplyr
library(tidyverse)
library(tm)
library(plyr)
library(sentimentr)

#charger les données
#avec le package readxl
df <- read.csv("C:\\Users\\ganci\\Documents\\master_miashs sans TER\\Analyse de données textuelles\\Projet\\Analyse_d_opinion\\Données\\corpus_bogdanof.csv",encoding = "UTF-8")
str(df)
```

```{r}
corpus <- get_sentences(df$post)
```



## sentiment par phrase 
```{r}
sentiment(corpus)
```




```{r}
sentiment_post <- sentiment_by(corpus)
```



```{r}
#premiers documents de la base de données
head(df)
```



```{r}
news_df = c('les gens pensent aux chiens','je deteste les fleurs', 
         'il est gentils et intelligents')

news_dfs  <- get_sentences(news_df)

sentiment(news_dfs)

```




```{r}
#présence des '\n' dans les commentaires
tmp <- grep("\n",df$post)
print(length(tmp))
```

```{r}
#lequels
print(head(tmp))
```





## TidyText - Premières explorations

#### Préparation des données

```{r}
#charger spécifiquement la libraire tidytext
library(tidytext)
```



La numérotation des documents permet de mieux comprendre les associations des termes avec les documents par la suite.

```{r}
#modifier la structure du tibble
#en numérotant les documents
DPRIM <- tibble(line=1:nrow(df),post=df$post)
print(head(DPRIM))
```



#### Tokenisation

Transformation des documents en une structure "tidy", en recensant les mots par document. L'information sur l'ordre des mots est perdue. On note en revanche que la casse a été changée, la ponctuation a été supprimée.

```{r}
#traiter le texte brut
res_A <- DPRIM %>%
  unnest_tokens(output=words,input=post)

#
print(res_A)
```

