data <-as.data.frame(matrix( sample( 2:20 , 20 , replace=T) , ncol=10))
colnames(data) <- c("math" , "english" , "biology" , "music" , "R-coding", "data-viz" , "french" , "physic", "statistic", "sport" )
data <-rbind(rep(20,10) , rep(0,10) , data)
set.seed(1)
data <-as.data.frame(matrix( sample( 2:20 , 20 , replace=T) , ncol=10))
colnames(data) <- c("math" , "english" , "biology" , "music" , "R-coding", "data-viz" , "french" , "physic", "statistic", "sport" )
data <-rbind(rep(20,10) , rep(0,10) , data)
View(data)
# Barplot
data %>% slice(c(3,4)) %>% t() %>% as.data.frame() %>% add_rownames() %>% arrange(V1) %>% mutate(rowname=factor(rowname, rowname)) %>%
ggplot( aes(x=rowname, y=V1)) +
geom_segment( aes(x=rowname ,xend=rowname, y=V2, yend=V1), color="grey") +
geom_point(size=5, color="#69b3a2") +
geom_point(aes(y=V2), size=5, color="#69b3a2", alpha=0.1) +
coord_flip() +
theme_ipsum() +
theme(
panel.grid.minor.y = element_blank(),
panel.grid.major.y = element_blank(),
axis.text = element_text( size=48 )
) +
ylim(0,20) +
ylab("mark") +
xlab("")
#################
library(ggplot2)
library(dplyr)
library(hrbrthemes)
# Data : auto-evaluation des compétences avant et après le Marathon du web
max = 20
min = 0
competences <-c("Gestion de projets", "Programmation", "Base de donnees", "Visualisation", "Analyse de donnees","Machine learning")
nb =length(competences)
avant = c(10, 10, 12, 10, 12, 10)
apres = c(15,14, 12, 16, 15.5, 12)
data <-as.data.frame(matrix(rbind(apres,avant),ncol=nb))
colnames(data) <- competences
data <-rbind(rep(20,nb) , rep(0,nb) , data)
# Barplot (avant en gris, après en vert, trié par gain de compétence)
data %>% slice(c(3,4)) %>% t() %>% as.data.frame() %>% add_rownames() %>% arrange(V1-V2) %>% mutate(rowname=factor(rowname, rowname)) %>%
ggplot( aes(x=rowname, y=V1)) +
geom_segment( aes(x=rowname ,xend=rowname, y=V2, yend=V1), color="grey") +
geom_point(size=5, color="#69b3a2") +
geom_point(aes(y=V2), size=5, color="#69b3a2", alpha=0.1) +
coord_flip() +
theme_ipsum() +
theme(
panel.grid.minor.y = element_blank(),
panel.grid.major.y = element_blank(),
axis.text = element_text( size=48 )
) +
ylim(min,max) +
ylab("Competences") +
xlab("")
#################
#################
library(ggplot2)
library(dplyr)
library(hrbrthemes)
# Data : auto-evaluation des compétences avant et après le Marathon du web
max = 20
min = 0
competences <-c("Gestion de projets", "Programmation", "Base de donnees", "Visualisation", "Analyse de donnees","Machine learning")
nb =length(competences)
avant = c(13, 13, 13, 13, 13, 13)
apres = c(15,14, 13, 15, 14, 14)
data <-as.data.frame(matrix(rbind(apres,avant),ncol=nb))
colnames(data) <- competences
data <-rbind(rep(20,nb) , rep(0,nb) , data)
# Barplot (avant en gris, après en vert, trié par gain de compétence)
data %>% slice(c(3,4)) %>% t() %>% as.data.frame() %>% add_rownames() %>% arrange(V1-V2) %>% mutate(rowname=factor(rowname, rowname)) %>%
ggplot( aes(x=rowname, y=V1)) +
geom_segment( aes(x=rowname ,xend=rowname, y=V2, yend=V1), color="grey") +
geom_point(size=5, color="#69b3a2") +
geom_point(aes(y=V2), size=5, color="#69b3a2", alpha=0.1) +
coord_flip() +
theme_ipsum() +
theme(
panel.grid.minor.y = element_blank(),
panel.grid.major.y = element_blank(),
axis.text = element_text( size=48 )
) +
ylim(min,max) +
ylab("Competences") +
xlab("")
#################
#################
library(ggplot2)
library(dplyr)
library(hrbrthemes)
# Data : auto-evaluation des compétences avant et après le Marathon du web
max = 20
min = 0
competences <-c("Gestion de projets", "Programmation", "Base de donnees", "Visualisation", "Analyse de donnees","Machine learning")
nb =length(competences)
avant = c(13, 13, 13, 13, 13, 13)
apres = c(15,15, 15.5, 15, 15, 15)
data <-as.data.frame(matrix(rbind(apres,avant),ncol=nb))
colnames(data) <- competences
data <-rbind(rep(20,nb) , rep(0,nb) , data)
# Barplot (avant en gris, après en vert, trié par gain de compétence)
data %>% slice(c(3,4)) %>% t() %>% as.data.frame() %>% add_rownames() %>% arrange(V1-V2) %>% mutate(rowname=factor(rowname, rowname)) %>%
ggplot( aes(x=rowname, y=V1)) +
geom_segment( aes(x=rowname ,xend=rowname, y=V2, yend=V1), color="grey") +
geom_point(size=5, color="#69b3a2") +
geom_point(aes(y=V2), size=5, color="#69b3a2", alpha=0.1) +
coord_flip() +
theme_ipsum() +
theme(
panel.grid.minor.y = element_blank(),
panel.grid.major.y = element_blank(),
axis.text = element_text( size=48 )
) +
ylim(min,max) +
ylab("Competences") +
xlab("")
#################
#################
library(ggplot2)
library(dplyr)
library(hrbrthemes)
# Data : auto-evaluation des compétences avant et après le Marathon du web
max = 20
min = 0
competences <-c("Gestion de projets", "Programmation", "Base de donnees", "Visualisation", "Analyse de donnees","Machine learning")
nb =length(competences)
avant = c(13, 13, 13, 13, 13, 13)
apres = c(15,15, 15.5, 15, 15, 15)
data <-as.data.frame(matrix(rbind(apres,avant),ncol=nb))
colnames(data) <- competences
data <-rbind(rep(20,nb) , rep(0,nb) , data)
# Barplot (avant en gris, après en vert, trié par gain de compétence)
data %>% slice(c(3,4)) %>% t() %>% as.data.frame() %>% add_rownames() %>% arrange(V1-V2) %>% mutate(rowname=factor(rowname, rowname)) %>%
ggplot( aes(x=rowname, y=V1)) +
geom_segment( aes(x=rowname ,xend=rowname, y=V2, yend=V1), color="grey") +
geom_point(size=5, color="#69b3a2") +
geom_point(aes(y=V2), size=5, color="#69b3a2", alpha=0.1) +
coord_flip() +
theme_ipsum() +
theme(
panel.grid.minor.y = element_blank(),
panel.grid.major.y = element_blank(),
axis.text = element_text( size=48 )
) +
ylim(min,max) +
ylab("Competences") +
xlab("")
#################
#################
library(ggplot2)
library(dplyr)
library(hrbrthemes)
# Data : auto-evaluation des compétences avant et après le Marathon du web
max = 20
min = 0
competences <-c("Gestion de projets", "Programmation", "Base de donnees", "Visualisation", "Analyse de donnees","Machine learning")
nb =length(competences)
avant = c(13, 13, 13, 13, 13, 13)
apres = c(15,15, 15.5, 15, 15, 15)
data <-as.data.frame(matrix(rbind(apres,avant),ncol=nb))
colnames(data) <- competences
data <-rbind(rep(20,nb) , rep(0,nb) , data)
# Barplot (avant en gris, après en vert, trié par gain de compétence)
data %>% slice(c(3,4)) %>% t() %>% as.data.frame() %>% add_rownames() %>% arrange(V1-V2) %>% mutate(rowname=factor(rowname, rowname)) %>%
ggplot( aes(x=rowname, y=V1)) +
geom_segment( aes(x=rowname ,xend=rowname, y=V2, yend=V1), color="grey") +
geom_point(size=5, color="#69b3a2") +
geom_point(aes(y=V2), size=5, color="#69b3a2", alpha=0.1) +
coord_flip() +
theme_ipsum() +
theme(
panel.grid.minor.y = element_blank(),
panel.grid.major.y = element_blank(),
axis.text = element_text( size=48 )
) +
ylim(min,max) +
ylab("Competences") +
xlab("")
#################
#################
library(ggplot2)
library(dplyr)
library(hrbrthemes)
# Data : auto-evaluation des compétences avant et après le Marathon du web
max = 20
min = 0
competences <-c("Gestion de projets", "Programmation", "Base de donnees", "Visualisation", "Analyse de donnees","Machine learning")
nb =length(competences)
avant = c(13, 13, 13, 13, 13, 13)
apres = c(15.5,15, 15.5, 15.5, 15, 15)
data <-as.data.frame(matrix(rbind(apres,avant),ncol=nb))
colnames(data) <- competences
data <-rbind(rep(20,nb) , rep(0,nb) , data)
# Barplot (avant en gris, après en vert, trié par gain de compétence)
data %>% slice(c(3,4)) %>% t() %>% as.data.frame() %>% add_rownames() %>% arrange(V1-V2) %>% mutate(rowname=factor(rowname, rowname)) %>%
ggplot( aes(x=rowname, y=V1)) +
geom_segment( aes(x=rowname ,xend=rowname, y=V2, yend=V1), color="grey") +
geom_point(size=5, color="#69b3a2") +
geom_point(aes(y=V2), size=5, color="#69b3a2", alpha=0.1) +
coord_flip() +
theme_ipsum() +
theme(
panel.grid.minor.y = element_blank(),
panel.grid.major.y = element_blank(),
axis.text = element_text( size=48 )
) +
ylim(min,max) +
ylab("Competences") +
xlab("")
#################
apres = c(15.5,15, 13, 15.5, 15.5, 15.5)
#dictionnaire - comptage
#ordonnancement selon la fréquence
dico_A <- res_A %>%
count(word,sort=TRUE)
#vider la mémoire
rm(list=ls())
#changer de dossier courant
# setwd("C:/Users/ricco/Desktop/demo")
#charger les packages de l'univers Tidy
#en particulier dplyr
library(tidyverse)
#charger les données
#avec le package readxl
D <- readxl::read_excel("C:\\Users\\ganci\\Documents\\master_miashs sans TER\\Analyse de données textuelles\\Projet\\Analyse_d_opinion\\video_tidytext\\imdb_reviews_1000.xlsx")
str(D)
#dictionnaire - comptage
#ordonnancement selon la fréquence
dico_A <- res_A %>%
count(word,sort=TRUE)
#dictionnaire - comptage
#ordonnancement selon la fréquence
dico_A <- res_A %>%
count(word,sort=TRUE)
#vider la mémoire
rm(list=ls())
#changer de dossier courant
# setwd("C:/Users/ricco/Desktop/demo")
#charger les packages de l'univers Tidy
#en particulier dplyr
library(tidyverse)
#charger les données
#avec le package readxl
D <- readxl::read_excel("C:\\Users\\ganci\\Documents\\master_miashs sans TER\\Analyse de données textuelles\\Projet\\Analyse_d_opinion\\video_tidytext\\imdb_reviews_1000.xlsx")
str(D)
#premiers documents de la base de données
head(D)
#inspection des classes
print(table(D$label))
#présence des '<br />' dans les commentaires
tmp <- grep("<br />",D$commentaires)
print(length(tmp))
#lequels
print(head(tmp))
#le premier par ex.
print(D$commentaires[1])
#le troisième par ex.
print(D$commentaires[3])
#présence des chiffres
#cf. expressions régulières sous R
#http://tutoriels-data-mining.blogspot.com/2017/01/les-expression-regulieres-sous-r.html
tmp <- grep('[0-9]',D$commentaires)
print(length(tmp))
#lesquels
print(head(tmp))
#le 2ème message
print(D$commentaires[2])
#le premier
print(D$commentaires[1])
#charger spécifiquement la libraire tidytext
library(tidytext)
#modifier la structure du tibble
#en numérotant les documents
DPRIM <- tibble(line=1:nrow(D),commentaires=D$commentaires)
print(head(DPRIM))
#traiter le texte brut
res_A <- DPRIM %>%
unnest_tokens(output=word,input=commentaires)
#
print(res_A)
#si on s'en tient aux mots du premier document
mots_1 <- res_A %>%
filter(line==1) %>%
select(word)
print(mots_1$word)
#pour rappel le 1er document était...
print(D$commentaires[1])
#dans le premier document
mots_1 %>%
group_by(word) %>%
count(sort=TRUE)
#comptage des termes par document
compte_A <- res_A %>%
group_by(line,word) %>%
summarize(freq=n())
print(compte_A)
#dictionnaire - comptage
#ordonnancement selon la fréquence
dico_A <- res_A %>%
count(word,sort=TRUE)
#affichage
print(dico_A)
install.packages("tm")
install.packages("tm")
library(tm)
stopwords("en")
stopwords("fr")
data(stopwords("fr"))
data("stopword")
data("stop_words")
#récupération des stopwords
data("stop_words")
print(stop_words)
#vider la mémoire
rm(list=ls())
#changer de dossier courant
# setwd("C:/Users/ricco/Desktop/demo")
#charger les packages de l'univers Tidy
#en particulier dplyr
library(tidyverse)
#charger les données
#avec le package readxl
D <- readxl::read_excel("C:\\Users\\ganci\\Documents\\master_miashs sans TER\\Analyse de données textuelles\\Projet\\Analyse_d_opinion\\video_tidytext\\imdb_reviews_1000.xlsx")
str(D)
#premiers documents de la base de données
head(D)
#inspection des classes
print(table(D$label))
#présence des '<br />' dans les commentaires
tmp <- grep("<br />",D$commentaires)
print(length(tmp))
#lequels
print(head(tmp))
#le premier par ex.
print(D$commentaires[1])
#le troisième par ex.
print(D$commentaires[3])
#présence des chiffres
#cf. expressions régulières sous R
#http://tutoriels-data-mining.blogspot.com/2017/01/les-expression-regulieres-sous-r.html
tmp <- grep('[0-9]',D$commentaires)
print(length(tmp))
#lesquels
print(head(tmp))
#le 2ème message
print(D$commentaires[2])
#le premier
print(D$commentaires[1])
#charger spécifiquement la libraire tidytext
library(tidytext)
#modifier la structure du tibble
#en numérotant les documents
DPRIM <- tibble(line=1:nrow(D),commentaires=D$commentaires)
print(head(DPRIM))
#traiter le texte brut
res_A <- DPRIM %>%
unnest_tokens(output=word,input=commentaires)
#
print(res_A)
#si on s'en tient aux mots du premier document
mots_1 <- res_A %>%
filter(line==1) %>%
select(word)
print(mots_1$word)
#pour rappel le 1er document était...
print(D$commentaires[1])
#dans le premier document
mots_1 %>%
group_by(word) %>%
count(sort=TRUE)
#comptage des termes par document
compte_A <- res_A %>%
group_by(line,word) %>%
summarize(freq=n())
print(compte_A)
#dictionnaire - comptage
#ordonnancement selon la fréquence
dico_A <- res_A %>%
count(word,sort=TRUE)
#affichage
print(dico_A)
#les termes les moins fréquents
print(tail(dico_A))
#récupération des stopwords
data("stop_words")
print(stop_words)
data("stop_words")
data("sentiments")
force(sentiments)
View(sentiments)
stopwords("fr")
#lexique pour l'analyse des sentiments
#polarité des termes - get_sentiments() de tidtytext
#"bing" est une source possible, il y en a d'autres
polarite_termes <- get_sentiments("bing")
print(polarite_termes)
#présence des '\n' dans les commentaires
tmp <- grep("\n",df$post)
#vider la mémoire
rm(list=ls())
#changer de dossier courant
# setwd("C:/Users/ricco/Desktop/demo")
#charger les packages de l'univers Tidy
#en particulier dplyr
library(tidyverse)
library(tm)
#charger les données
#avec le package readxl
df <- read.csv("C:\\Users\\ganci\\Documents\\master_miashs sans TER\\Analyse de données textuelles\\Projet\\Analyse_d_opinion\\Données\\corpus_bogdanof.csv",encoding = "UTF-8")
str(df)
#premiers documents de la base de données
head(df)
#présence des '\n' dans les commentaires
tmp <- grep("\n",df$post)
print(length(tmp))
#lequels
print(head(tmp))
library(sentimentr)
#vider la mémoire
rm(list=ls())
#changer de dossier courant
# setwd("C:/Users/ricco/Desktop/demo")
#charger les packages de l'univers Tidy
#en particulier dplyr
library(tidyverse)
library(tm)
library(plyr)
install.packages("plyr")
install.packages("sentimentr")
#vider la mémoire
rm(list=ls())
#changer de dossier courant
# setwd("C:/Users/ricco/Desktop/demo")
#charger les packages de l'univers Tidy
#en particulier dplyr
library(tidyverse)
library(tm)
library(plyr)
library(sentimentr)
#charger les données
#avec le package readxl
df <- read.csv("C:\\Users\\ganci\\Documents\\master_miashs sans TER\\Analyse de données textuelles\\Projet\\Analyse_d_opinion\\Données\\corpus_bogdanof.csv",encoding = "UTF-8")
str(df)
View(df)
#vider la mémoire
rm(list=ls())
#changer de dossier courant
# setwd("C:/Users/ricco/Desktop/demo")
#charger les packages de l'univers Tidy
#en particulier dplyr
library(tidyverse)
library(tm)
library(plyr)
library(sentimentr)
#charger les données
#avec le package readxl
df <- read.csv("C:\\Users\\ganci\\Documents\\master_miashs sans TER\\Analyse de données textuelles\\Projet\\Analyse_d_opinion\\Données\\corpus_bogdanof.csv",encoding = "UTF-8")
str(df)
#vider la mémoire
rm(list=ls())
#changer de dossier courant
# setwd("C:/Users/ricco/Desktop/demo")
#charger les packages de l'univers Tidy
#en particulier dplyr
library(tidyverse)
library(tm)
library(plyr)
library(sentimentr)
#charger les données
#avec le package readxl
df <- read.csv("C:\\Users\\ganci\\Documents\\master_miashs sans TER\\Analyse de données textuelles\\Projet\\Analyse_d_opinion\\Données\\corpus_bogdanof.csv",encoding = "UTF-8")
str(df)
corpus <- get_sentences(df$post)
corpus
sentiment(corpus)
sentiment_post <- sentiment_by(corpus)
sentiment_post
news_df = c('les gens pensent aux chiens','je deteste les fleurs',
'il est gentils et intelligents')
news_df = c('les gens pensent aux chiens','je deteste les fleurs',
'il est gentils et intelligents')
news_dfs  <- get_sentences(news_df)
news_df
news_dfs
news_df = c('les gens pensent aux chiens','je deteste les fleurs',
'il est gentils et intelligents')
news_dfs  <- get_sentences(news_df)
sentiment(news_dfs)
View(news_dfs)
View(news_dfs)
news_dfs  <- get_sentences(news_df) %>% as.data.frame()
View(news_dfs)
corpus <- get_sentences(df$post)
View(corpus)
sentencespos <- get_sentences(df$post) %>% data.frame()
#vider la mémoire
rm(list=ls())
#changer de dossier courant
# setwd("C:/Users/ricco/Desktop/demo")
#charger les packages de l'univers Tidy
#en particulier dplyr
library(tidyverse)
library(tm)
library(plyr)
library(sentimentr)
#charger les données
#avec le package readxl
df <- read.csv("C:\\Users\\ganci\\Documents\\master_miashs sans TER\\Analyse de données textuelles\\Projet\\Analyse_d_opinion\\Données\\corpus_bogdanof.csv",encoding = "UTF-8")
str(df)
corpus <- get_sentences(df$post)
sentencespos <- get_sentences(df$post) %>% data.frame()
View(corpus)
